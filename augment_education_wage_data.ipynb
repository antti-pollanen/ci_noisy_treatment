{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import data.data_utils as data_utils\n",
    "import data.education_wage_original_data_generator as education_wage_original_data_generator\n",
    "import models.model_fitting as model_fitting\n",
    "import models.model_mlp as model_mlp\n",
    "import utils\n",
    "\n",
    "print(\"executing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 1234\n",
    "utils.set_random_seeds(task_id)\n",
    "\n",
    "params = {\n",
    "    \"case_id\": task_id,\n",
    "    \"n_train\": 2990, \n",
    "    \"n_validate\": 0,\n",
    "    \"n_test\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"decoder_hidden_sizes\": [30, 30, 30, 30, 30],\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"max_epochs\": 5000,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"lr_reducer_patience\": 50,\n",
    "    \"lr_reducer_factor\": 0.1,\n",
    "    \"patience_in_epochs\": 100,\n",
    "    \"adam_beta_1\": 0.97,\n",
    "    \"adam_beta_2\": 0.997,\n",
    "    \"max_training_time_s\": 600000, \n",
    "    \"outcome\": \"lwage\",\n",
    "    \"uses_t_instead_of_w\": True,\n",
    "    \"num_q_annealing_epochs\": 1,\n",
    "    \"q_initial_weight\": 1.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "output = {}\n",
    "\n",
    "time_start_s: float = time.monotonic()\n",
    "\n",
    "data_generator = education_wage_original_data_generator.Generator(\n",
    "    params[\"outcome\"]\n",
    ")\n",
    "\n",
    "train_data = data_generator.generate_data(params[\"n_train\"])\n",
    "validate_data = (\n",
    "    data_generator.generate_data(params[\"n_validate\"])\n",
    "    if params[\"n_validate\"] > 0\n",
    "    else train_data\n",
    ")\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, batch_size=params[\"batch_size\"], shuffle=True\n",
    ")\n",
    "\n",
    "output[\"time_data_generated_s\"] = time.monotonic() - time_start_s\n",
    "\n",
    "time_start_s = time.monotonic()\n",
    "\n",
    "model = model_mlp.Mlp(\n",
    "    z_dim=train_data.z.shape[1],\n",
    "    hidden_sizes=params[\"decoder_hidden_sizes\"],\n",
    "    uses_t_instead_of_w=params[\"uses_t_instead_of_w\"],\n",
    ")\n",
    "\n",
    "output[\"time_model_created_s\"] = time.monotonic() - time_start_s\n",
    "time_start_s = time.monotonic()\n",
    "\n",
    "output[\"was_run_interrupted_due_to_time\"] = model_fitting.fit_model(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    validate_data=validate_data,\n",
    "    learning_rate=params[\"learning_rate\"],\n",
    "    max_epocs=params[\"max_epochs\"],\n",
    "    weight_decay=params[\"weight_decay\"],\n",
    "    num_q_annealing_epochs=params[\"num_q_annealing_epochs\"],\n",
    "    q_initial_weight=params[\"q_initial_weight\"],\n",
    "    lr_reducer_patience=params[\"lr_reducer_patience\"],\n",
    "    lr_reducer_factor=params[\"lr_reducer_factor\"],\n",
    "    patience_in_epochs=params[\"patience_in_epochs\"],\n",
    "    adam_beta_1=params[\"adam_beta_1\"],\n",
    "    adam_beta_2=params[\"adam_beta_2\"],\n",
    "    max_training_time_s=params[\"max_training_time_s\"],\n",
    ")\n",
    "\n",
    "output[\"time_model_trained_s\"] = time.monotonic() - time_start_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "output[\"git_commit_hash\"] = repo.head.object.hexsha\n",
    "\n",
    "output[\"params\"] = params\n",
    "\n",
    "output[\"train_y_sd_estimate\"] = model.get_y_sd_estimate(\n",
    "        torch.from_numpy(train_data.z),\n",
    "        torch.from_numpy(train_data.t),\n",
    "        torch.from_numpy(train_data.y),\n",
    "    )\n",
    "\n",
    "output[\"validate_y_sd_estimate\"] = model.get_y_sd_estimate(\n",
    "        torch.from_numpy(validate_data.z),\n",
    "        torch.from_numpy(validate_data.t),\n",
    "        torch.from_numpy(validate_data.y),\n",
    "    )\n",
    "\n",
    "output[\"train_loss\"] = (\n",
    "    model.loss(\n",
    "        batch=[\n",
    "            torch.tensor(train_data.z),\n",
    "            torch.tensor(train_data.t),\n",
    "            torch.tensor(train_data.w),\n",
    "            torch.tensor(train_data.y),\n",
    "            None,\n",
    "        ]\n",
    "    )\n",
    "    .detach()\n",
    "    .item()\n",
    ")\n",
    "output[\"validate_loss\"] = (\n",
    "    model.loss(\n",
    "        batch=[\n",
    "            torch.tensor(validate_data.z),\n",
    "            torch.tensor(validate_data.t),\n",
    "            torch.tensor(validate_data.w),\n",
    "            torch.tensor(validate_data.y),\n",
    "            None,\n",
    "        ]\n",
    "    )\n",
    "    .detach()\n",
    "    .item()\n",
    ")\n",
    "\n",
    "out_dir = \"data/education_wage_data/\"\n",
    "print(\"Output:\")\n",
    "print(json.dumps(output, sort_keys=True, indent=4))\n",
    "with open(out_dir+\"augmenting_model_output.json\", \"w\") as f:\n",
    "    json.dump(output, f, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sd_multiplier = 0.1\n",
    "w_sds = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, out_dir+\"education_wage_augmenting_model.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_random_seeds(479)\n",
    "\n",
    "y_noise_estimate = model.get_y_sd_estimate(\n",
    "            torch.tensor(train_data.z),\n",
    "            torch.tensor(train_data.t),\n",
    "            torch.tensor(train_data.y),\n",
    "        )\n",
    "\n",
    "print(\"y_noise_estimate:\")\n",
    "print(y_noise_estimate)\n",
    "\n",
    "y_sd = y_sd_multiplier*y_noise_estimate\n",
    "\n",
    "z = data_generator.z\n",
    "t = data_generator.t\n",
    "\n",
    "mean_estimates = model(torch.tensor(z), torch.tensor(t)).detach()\n",
    "print(\"mean_estimates:\")\n",
    "print(mean_estimates)\n",
    "\n",
    "generated_y = np.random.normal(loc=mean_estimates, scale=y_sd).astype(np.float32)\n",
    "print(\"generated_y:\")\n",
    "print(generated_y)\n",
    "\n",
    "for w_sd in w_sds:\n",
    "    noise = np.random.normal(0, w_sd * t.std(), t.shape).astype(np.float32)\n",
    "    dataset = data_utils.MeDataset(z = z, t = t, w = t + noise.reshape((-1,1)), y = generated_y)\n",
    "    torch.save(dataset, out_dir+f\"education_wage_data_augmented_noise_{int(100*w_sd)}_percent.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir+\"y_sd.txt\", \"w\") as f:\n",
    "    f.write(str(y_sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of available features: \", data_generator.z.shape[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_no_noise.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python generic (scicomp-python-env/2024-01)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
